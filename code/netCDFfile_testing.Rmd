---
title: "Physical data timeseries"
author: 'By: Claire Gonzales'
date: "2023-04-21"
output: html_document
---

This rmd is to extract data from the NetCDF files and create a matrix with that information that can feed into the bivalve model. I want monthly averaged data with the sites on the y axis (as rows) and each of the 18 months on the x axis (as columns). I have data for 4 types of physical data. I am going to try and format them all the same way.


```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)

library(tidyverse)
library(here)
library(paletteer)
library(ggplot2)
library(ncdf4)
library(sp)
library(raster) # package for raster manipulation (will be retired Oct 2023)
library(rgdal) # package for geospatial analysis
library(terra) # updated verson of raster package
library(backports) # for startsWith()
```

First need to reformat the csv to be able to put it into python and get physical data

```{r, eval=FALSE, include=FALSE}
#reading in csv, making it long form data and writing csv to export that new format of the data

sites <- read_csv(here("data", "bivalve_model", "poc_data", "test3.csv")) %>% 
  pivot_longer(cols = oct_14:march_16, names_to = "date", values_to = "poc" )

#write_csv(sites, here("data", "bivalve_model","poc_data","test3_long.csv"))

```


############# Use NASA files to extract data & fill matrix ###################

```{r}
# extracting locations for sites and creating vectors

sites <- read.csv(here("data", "bivalve_model", "bivalvemodel_sites_5000pts_TableToExcel.csv"))

sites_lat <- as.numeric(sites$latitude)
sites_lon <- as.numeric(sites$longitude)

```


```{r}
# some example code that will help fugure out the forloop 
# ncfile_1 <- nc_open( here("data", "bivalve_model","poc_data",  "AQUA_MODIS.20160301_20160331.L3m.MO.POC.poc.4km.nc"), write=TRUE, readunlim=TRUE, verbose=FALSE, auto_GMT=TRUE, suppress_dimvals=FALSE, return_on_error=FALSE )
# 
# attributes(ncfile_1$var)
# attributes(ncfile_1$dim)
```

```{r, include=FALSE, eval=FALSE}
# lat <- ncvar_get(ncfile_1, "lat")
# nlat <- dim(lat)
# 
# lon <- ncvar_get(ncfile_1, "lon")
# nlon <- dim(lon) 
# 
# month <- march

```

#################### Wrangling NetCDF Files ####################

# Mixed layer depth
```{r}
## looking at the data
ncfile_mix <- nc_open( here("data", "bivalve_model","data_NetCDF", "ECCO_L4_MIXED_LAYER_DEPTH_05DEG_MONTHLY_V4R4",  "OCEAN_MIXED_LAYER_DEPTH_mon_mean_2014-10_ECCO_V4r4_latlon_0p50deg.nc"), write=TRUE, readunlim=TRUE, verbose=FALSE, auto_GMT=TRUE, suppress_dimvals=FALSE, return_on_error=FALSE )

attributes(ncfile_mix$var)
attributes(ncfile_mix$dim)

## lat and long names:
## "latitude" and "longitude"
```

## Reading in files 
```{r}
mix_files <- list.files(path = "/Users/clairegonzales/Documents/R projects/chap_2_sitingstudy/chap2/data/bivalve_model/data_NetCDF/ECCO_L4_MIXED_LAYER_DEPTH_05DEG_MONTHLY_V4R4", pattern = "*.nc")

```

# Organizing data frames (example file)
```{r, eval=FALSE, include=FALSE}
lat <- ncvar_get(ncfile_mix, "latitude")
nlat <- dim(lat)

lon <- ncvar_get(ncfile_mix, "longitude")
nlon <- dim(lon) 

lonlat <- as.matrix(expand.grid(lon, lat))


mix_array <- ncvar_get(ncfile_mix, "MXLDEPTH")
nmix <- dim(mix_array)

mix_vec_long <- as.vector(mix_array)
length(mix_vec_long)


mix_obs <- data.frame(cbind(lonlat, mix_vec_long)) %>% #data in tidy format
  rename("Long" = "Var1",
         "Lat" = "Var2",
         "Mixed_Layer_Depth" = "mix_vec_long")

r <- rasterFromXYZ(mix_obs, crs=CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs+ towgs84=0,0,0"))

```

Trying to for loop() through data to first gather metrics for each site (nested for loop()) and for each month (outer for loop())
## for looping through files
```{r}

# setting wd to our data file so that R can find everything
setwd("/Users/clairegonzales/Documents/R projects/chap_2_sitingstudy/chap2/data/bivalve_model/data_NetCDF/ECCO_L4_MIXED_LAYER_DEPTH_05DEG_MONTHLY_V4R4")

# create a holding vector/matrix
# this holding vector will be 18 columns across and 5000 long. Each cell will have monthly averaged data for each of the 5000 site points
holding <- as_data_frame(matrix(data = NaN, nrow = nrow(sites), ncol = 18))

#first for loop()
for(i in 1:length(mix_files)){
  
  #open each file
  file <- mix_files[i]
  
  nc_open(file, write=TRUE, readunlim=TRUE, verbose=FALSE, auto_GMT=TRUE, suppress_dimvals=FALSE, return_on_error=FALSE)
  
  
  r <- brick(file, varname = "MXLDEPTH")
  
  
  #nested for loop to extract data for each coordinate
  for(j in 1:nrow(sites)){
    
    temp_lon <- sites_lon[j]
    temp_lat <- sites_lat[j]
    
    extract_metric <- raster::extract(r, SpatialPoints(cbind(temp_lon, temp_lat)), method='simple')
    
    ## trying to create a vector with all the extracted metrics from all the coordinates 1:nrow(sites)
    ## this vector is one month of data for all 5,000 site locations ##
    holding[j,i] <-  extract_metric 
    
  }
  colname = mix_files[i] %>% str_split(pattern = "_") %>% unlist()
  colnames(holding)[i] = colname[7]
     
  nc_close(nc_open(file))
}

matrix_mix <- data.frame(cbind(sites_lon, sites_lat, holding))

#resetting our wd to home
setwd("/Users/clairegonzales/Documents/R projects/chap_2_sitingstudy/chap2")
```



# Surface temperature
```{r, include=FALSE, eval=FALSE}
# Example to get an idea of how the for loop() should look
ncfile_sst <- here("data", "bivalve_model","data_NetCDF", "OceanColor_SST",  "AQUA_MODIS.20141001_20141031.L3m.MO.SST.sst.4km.nc")

nc_open(ncfile_sst, write=TRUE, readunlim=TRUE, verbose=FALSE, auto_GMT=TRUE, suppress_dimvals=FALSE, return_on_error=FALSE)

attributes(ncfile_sst$var)
attributes(ncfile_sst$dim)

print(ncfile_sst)

r <- brick(ncfile_sst, varname = "sst")

temp_lon <- sites_lon[1]
temp_lat <- sites_lat[1]
    
extract_metric <- raster::extract(r, SpatialPoints(cbind(temp_lon, temp_lat)), method='simple')

extract_metric
## lat and long names:
## "lat" and "lon"
```

## Reading in files 
```{r}
sst_files <- list.files(path = "/Users/clairegonzales/Documents/R projects/chap_2_sitingstudy/chap2/data/bivalve_model/data_NetCDF/OceanColor_SST", pattern = "*.nc")
```

## for looping through files
```{r}

# setting wd to our data file so that R can find everything
setwd("/Users/clairegonzales/Documents/R projects/chap_2_sitingstudy/chap2/data/bivalve_model/data_NetCDF/OceanColor_SST")

# create a holding vector/matrix
# this holding vector will be 18 columns across and 5000 long. Each cell will have monthly averaged data for each of the 5000 site points
holding <- as_data_frame(matrix(data = NaN, nrow = nrow(sites), ncol = length(sst_files)))

#first for loop()
for(i in 1:length(sst_files)){
  
  #open each file
  file <- sst_files[i]
  
  nc_open(file, write=TRUE, readunlim=TRUE, verbose=FALSE, auto_GMT=TRUE, suppress_dimvals=FALSE, return_on_error=FALSE)
  
  
  r <- brick(file, varname = "sst")
  
  
  #nested for loop to extract data for each coordinate
  for(j in 1:nrow(sites)){
    
    temp_lon <- sites_lon[j]
    temp_lat <- sites_lat[j]
    
    extract_metric <- raster::extract(r, SpatialPoints(cbind(temp_lon, temp_lat)), method='simple')
    
    ## trying to create a vector with all the extracted metrics from all the coordinates 1:nrow(sites)
    ## this vector is one month of data for all 5,000 site locations ##
    holding[j,i] <-  extract_metric 
    
  }
  colname = sst_files[i] %>% str_split(pattern = "_") %>% unlist()
  colnames(holding)[i] = colname[2]
     
  nc_close(nc_open(file))
}

matrix_sst <- data.frame(cbind(sites_lon, sites_lat, holding))

#resetting our wd to home
setwd("/Users/clairegonzales/Documents/R projects/chap_2_sitingstudy/chap2")
```


# Current veloicty
```{r, eval=FALSE}
ncfile_current <- nc_open(here("data", "bivalve_model","data_NetCDF", "OSCAR_L4_OC_FINAL_V2.0",  "oscar_currents_final_20141001.nc"))

print(ncfile_current)

attributes(ncfile_current$var)
attributes(ncfile_current$dim)

r <- raster(ncfile_current, varname = "", crs=CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs+ towgs84=0,0,0"))

## lat and long names:
## "latitude" and "longitude"
```

## Reading in files 
```{r}
curvel_files <- list.files(path = "/Users/clairegonzales/Documents/R projects/chap_2_sitingstudy/chap2/data/bivalve_model/data_NetCDF/OSCAR_L4_OC_FINAL_V2.0", pattern = "*.nc")
```

## ZONAL CURRENTS: for looping through files
```{r}

# setting wd to our data file so that R can find everything
setwd("/Users/clairegonzales/Documents/R projects/chap_2_sitingstudy/chap2/data/bivalve_model/data_NetCDF/OSCAR_L4_OC_FINAL_V2.0")

# create a holding vector/matrix
# this holding vector will be 18 columns across and 5000 long. Each cell will have monthly averaged data for each of the 5000 site points
holding <- as_data_frame(matrix(data = NaN, nrow = nrow(sites), ncol = length(curvel_files)))

#first for loop()
for(i in 1:length(curvel_files)){
  
  #open each file
  file <- curvel_files[i]
  nc_open(file)
  
  # file <- nc_open(curvel_files[i])
  
  # nc_open(file, write=TRUE, readunlim=TRUE, verbose=FALSE, auto_GMT=TRUE, suppress_dimvals=FALSE, return_on_error=FALSE)
  
  #pull the lat and lon variables from each nc file and create a long matrix of those coordinates
  # lat <- ncvar_get(file, "lat")
  # lon <- ncvar_get(file, "lon")
  # lonlat <- as.matrix(expand.grid(lon, lat))
  # #pull the mixed layer depth variable
  # curvel_array <- ncvar_get(file, "u")
  # 
  # #turn that array into a vector
  # curvel_vec_long <- as.vector(curvel_array)
  # 
  # #create a data frame of the lat, lon and mixed layer depth
  # df <- data.frame(cbind(lonlat, curvel_vec_long)) %>% #data in tidy format
  # rename("Long" = "Var1",
  #        "Lat" = "Var2",
  #        "Current_Velocity_Zonal" = "curvel_vec_long")
  # 
  # #turn this data frame into a raster
  # r <- rasterFromXYZ(df, crs=CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs+ towgs84=0,0,0"))
  
   # r <- brick(file, varname = "u")
   
   r <- rast(file)
   ext(r)=c(-180, 180, -90, 90)
  
  #nested for loop to extract data for each coordinate
  for(j in 1:nrow(sites)){
    
    temp_lon <- sites_lon[j]
    temp_lat <- sites_lat[j]
    
    extract_metric <- terra::extract(r[names(r)[1]], vect(cbind(temp_lon, temp_lat), crs="+proj=longlat +datum=WGS84"), method="simple", cells=FALSE, xy=FALSE)
    
    ## create vector with all the extracted metrics from all the coordinates 1:nrow(sites)
    ## this vector is one month of data for all 5,000 site locations ##
    holding[j,i] <-  extract_metric$u
    
  }
  colname = curvel_files[i] %>% str_split(pattern = "_") %>% unlist()
  colnames(holding)[i] = colname[4]
     
  nc_close(nc_open(file))
}

matrix_curvel_zonal <- data.frame(cbind(sites_lon, sites_lat, holding))

#resetting our wd to home
setwd("/Users/clairegonzales/Documents/R projects/chap_2_sitingstudy/chap2")
```

## MERIDIONAL CURRENTS: for looping through files
```{r}
# setting wd to our data file so that R can find everything
setwd("/Users/clairegonzales/Documents/R projects/chap_2_sitingstudy/chap2/data/bivalve_model/data_NetCDF/OSCAR_L4_OC_FINAL_V2.0")

# create a holding vector/matrix
# this holding vector will be 18 columns across and 5000 long. Each cell will have monthly averaged data for each of the 5000 site points
holding <- as_data_frame(matrix(data = NaN, nrow = nrow(sites), ncol = length(curvel_files)))

#first for loop()
for(i in 1:length(curvel_files)){
  
  #open each file
  file <- curvel_files[i]
  nc_open(file)
  
  #turn this data frame into a raster
  r <- rast(file)
  ext(r)=c(-180, 180, -90, 90)
  
  
  #nested for loop to extract data for each coordinate
  for(j in 1:nrow(sites)){
    
    temp_lon <- sites_lon[j]
    temp_lat <- sites_lat[j]
    
    extract_metric <- terra::extract(r[names(r)[3]], vect(cbind(temp_lon, temp_lat), crs="+proj=longlat +datum=WGS84"), method="simple", cells=FALSE, xy=FALSE)
    
    ## create vector with all the extracted metrics from all the coordinates 1:nrow(sites)
    ## this vector is one month of data for all 5,000 site locations ##
    holding[j,i] <-  extract_metric$v
    
  }
  colname = curvel_files[i] %>% str_split(pattern = "_") %>% unlist()
  colnames(holding)[i] = colname[4]
     
  nc_close(nc_open(file))
}

matrix_curvel_meridional <- data.frame(cbind(sites_lon, sites_lat, holding))

#resetting our wd to home
setwd("/Users/clairegonzales/Documents/R projects/chap_2_sitingstudy/chap2")
```

# POC
```{r}
ncfile_poc <- nc_open( here("data", "bivalve_model","data_NetCDF", "OceanColor_POC",  "AQUA_MODIS.20141001_20141031.L3m.MO.POC.poc.4km.nc"), write=TRUE, readunlim=TRUE, verbose=FALSE, auto_GMT=TRUE, suppress_dimvals=FALSE, return_on_error=FALSE )

print(ncfile_poc)

attributes(ncfile_poc$var)
attributes(ncfile_poc$dim)

## lat and long names:
## "lat" and "lon"
```

## Reading in files 
```{r}
poc_files <- list.files(path = "/Users/clairegonzales/Documents/R projects/chap_2_sitingstudy/chap2/data/bivalve_model/data_NetCDF/OceanColor_POC", pattern = "*.nc")
```

## for looping through files
```{r}

# setting wd to our data file so that R can find everything
setwd("/Users/clairegonzales/Documents/R projects/chap_2_sitingstudy/chap2/data/bivalve_model/data_NetCDF/OceanColor_POC")

# create a holding vector/matrix
# this holding vector will be 18 columns across and 5000 long. Each cell will have monthly averaged data for each of the 5000 site points
holding <- as_data_frame(matrix(data = NaN, nrow = nrow(sites), ncol = length(poc_files)))

#first for loop()
for(i in 1:length(poc_files)){
  
  #open each file
  file <- poc_files[i]
  
  nc_open(file, write=TRUE, readunlim=TRUE, verbose=FALSE, auto_GMT=TRUE, suppress_dimvals=FALSE, return_on_error=FALSE)
  
  
  r <- brick(file, varname = "poc")
  
  
  #nested for loop to extract data for each coordinate
  for(j in 1:nrow(sites)){
    
    temp_lon <- sites_lon[j]
    temp_lat <- sites_lat[j]
    
    extract_metric <- raster::extract(r, SpatialPoints(cbind(temp_lon, temp_lat)), method='simple')
    
    ## trying to create a vector with all the extracted metrics from all the coordinates 1:nrow(sites)
    ## this vector is one month of data for all 5,000 site locations ##
    holding[j,i] <-  extract_metric 
    
  }
  colname = poc_files[i] %>% str_split(pattern = "_") %>% unlist()
  colnames(holding)[i] = colname[2]
     
  nc_close(nc_open(file))
}

matrix_poc <- data.frame(cbind(sites_lon, sites_lat, holding))

#resetting our wd to home
setwd("/Users/clairegonzales/Documents/R projects/chap_2_sitingstudy/chap2")
```

##wrangling current velocity data
```{r}

## Attempting to pivot longer and then group by and summarize/mean ##

long_matrix_curvel_zonal <- matrix_curvel_zonal %>% 
  pivot_longer(cols = starts_with("X20"), names_to = "day", values_to = "velocity")

#####################################################################

names <- colnames(matrix_curvel_zonal)

vector550 <- c(1:550)

table_names <- cbind(names, vector550)

oct14 <- matrix_curvel_zonal %>% 
  dplyr::select(3:33) %>% 
  mutate(oct14_mean = mean(1:31)) %>% 
  rowMeans()

##PICK UP HERE##
nov14 <- matrix_curvel_zonal %>% 
  dplyr::select(34:63)

dec14 <- matrix_curvel_zonal %>% 
  dplyr::select(64:94)

jan15 <- matrix_curvel_zonal %>% 
  dplyr::select(95:125)

feb15 <- matrix_curvel_zonal %>% 
  dplyr::select(126:153)

mar15 <- matrix_curvel_zonal %>% 
  dplyr::select(154:184)

ap15 <- matrix_curvel_zonal %>% 
  dplyr::select(185:214)

may15 <- matrix_curvel_zonal %>% 
  dplyr::select(215:245)

jun15 <- matrix_curvel_zonal %>% 
  dplyr::select(246:275)

jul15 <- matrix_curvel_zonal %>% 
  dplyr::select(276:306)

aug15 <- matrix_curvel_zonal %>% 
  dplyr::select(307:337)

sep15 <- matrix_curvel_zonal %>% 
  dplyr::select(338:367)

oct15 <- matrix_curvel_zonal %>% 
  dplyr::select(368:398)

nov15 <- matrix_curvel_zonal %>% 
  dplyr::select(399:428)

dec15 <- matrix_curvel_zonal %>% 
  dplyr::select(429:459)

jan16 <- matrix_curvel_zonal %>% 
  dplyr::select(460:490)

feb16 <- matrix_curvel_zonal %>% 
  dplyr::select(491:519)

mar16 <- matrix_curvel_zonal %>% 
  dplyr::select(520:550)

### Add the mean to each subset and then cbind all the means together ###

matrix_curvel_zonal_ave <- matrix_curvel_zonal %>% 
  dplyr::summarize(
    X201410_ave = mean(dplyr::select(matrix_curvel_zonal, starts_with("X201410")), na.rm = TRUE),
    X201411_ave = mean(dplyr::select(matrix_curvel_zonal, starts_with("X201411")), na.rm = TRUE),
    X201412_ave = mean(dplyr::select(matrix_curvel_zonal, starts_with("X201412")), na.rm = TRUE),
    X201501_ave = mean(dplyr::select(matrix_curvel_zonal, starts_with("X201501")), na.rm = TRUE),
    X201502_ave = mean(dplyr::select(matrix_curvel_zonal, starts_with("X201502")), na.rm = TRUE),
    X201503_ave = mean(dplyr::select(matrix_curvel_zonal, starts_with("X201503")), na.rm = TRUE),
    X201504_ave = mean(dplyr::select(matrix_curvel_zonal, starts_with("X201504")), na.rm = TRUE),
    X201505_ave = mean(dplyr::select(matrix_curvel_zonal, starts_with("X201505")), na.rm = TRUE),
    X201506_ave = mean(dplyr::select(matrix_curvel_zonal, starts_with("X201506")), na.rm = TRUE),
    X201507_ave = mean(dplyr::select(matrix_curvel_zonal, starts_with("X201507")), na.rm = TRUE),
    X201508_ave = mean(dplyr::select(matrix_curvel_zonal, starts_with("X201508")), na.rm = TRUE),
    X201509_ave = mean(dplyr::select(matrix_curvel_zonal, starts_with("X201509")), na.rm = TRUE),
    X201510_ave = mean(dplyr::select(matrix_curvel_zonal, starts_with("X201510")), na.rm = TRUE),
    X201511_ave = mean(dplyr::select(matrix_curvel_zonal, starts_with("X201511")), na.rm = TRUE),
    X201512_ave = mean(dplyr::select(matrix_curvel_zonal, starts_with("X201512")), na.rm = TRUE),
    X201601_ave = mean(dplyr::select(matrix_curvel_zonal, starts_with("X201601")), na.rm = TRUE),
    X201602_ave = mean(dplyr::select(matrix_curvel_zonal, starts_with("X201602")), na.rm = TRUE),
    X201603_ave = mean(dplyr::select(matrix_curvel_zonal, starts_with("X201603")), na.rm = TRUE)
    ) 

# data_curvel <- data.frame(
#   merge(matrix_curvel_zonal, matrix_curvel_meridional, by = c("sites_lon", "sites_lat"))
# ) %>% 
#   mutate(X201410_ave = mean(select()))

```


# creating full data frame
```{r, eval=FALSE}
data_mixsst <- data.frame(
  merge(matrix_mix, matrix_sst, by = c("sites_lon", "sites_lat"))
)

#### Code to wrangle daily data and make it monthly data ####
### must also use pathagorean theorem for reconciling velocities ###
##########################################################################
data_curvel <- data.frame(
  merge(matrix_curvel_zonal, matrix_curvel_meridional, by = c("sites_lon", "sites_lat")) %>% 
    mutate()
  )

data_curvelpoc <- data.frame(
  merge(data_curvel, matrix_poc, by = c("sites_lon", "sites_lat"))
)

alldata <- data.frame(
  merge(data_mixsst, data_curvelpoc, by = c("sites_lon", "sites_lat"))
)
```

## write csv of all data dataframe

```{r}
#write.csv(alldata, here("data", "alldata_forbivalvemodel.csv"))
```

## writing in new csv of the data
This data frame has been adjusted to make the daily current velocity data a monthly average

```{r, eval=FALSE}
new_data <- read.csv(here("data", "bivalve_model", "celldata3.csv"), header = FALSE) %>% 
  na.omit() %>% # removing lines with any NAs in any columns
  dplyr::select(!1) 

write.csv(new_data, here("data", "celldata4.csv"), col.names = F)
```

